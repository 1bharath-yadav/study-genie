ok you understand my project very well again we dont store user uploaded documents in database (we only use numpyz for storing uploaded files of studets and after its usse we delete them).now give me the backend structure creatable linux mkdir ..commands from rooot dir and explain what is the functioonality of each file and folder.make sure wwe are building asynchronousable and cacheble and all modern efficent rag and data management project named as study genie.you got me wrong, dont mess with llm things like data embedding storing and chunksstoring, we never store user doccuemts permenently.in lanchain orchastrater we just take user question +uploaded file then chunking and embedding storingin numpyz(as user docs is not very big)and retriving and give chunks to llm and get structured respone.  this is not problem at all the prblem how we store student each subject and how we update and add new subjects autometically,how to track progress(on which based and what to store)how to store user weakness and that concept and overall personalized suggestions....and lot more tracking for student effective learning.i have one confusion about how to store user data like data schema which track student learning and progress and all user data. for example if user uploads chemistry pdf and workout this subject whole data,next day he may ask about any subject,so my idea is when giving top chinks to llm while extracting structured format we willask for subject name in single word ,if that word is not in our database we will create new column if already exist we add the details to that column.  i am confusing about all these database schema automation and storing stdent  analytics for student progress.give me effective plan,process and which modern database is best suitable.
I am building rag model in enhances self and personalized learning,i have to take student notes in pdfs,images,and  common study data format (extract the data if text is not selextable by any other functions) .2.we will store whole data and perform chunking and then embedding (by  numpysavez) and store embeddings in numpyz.  if user is asked extraquestions we also take account that. at first we will generate embeddings for user prompt and then grep the chunks by hybrid fetch(keyword+vector based)  then give those fetched chunks and around chunks to llm. and by llm extractionfor structured output and json schema(example   {{flashcards:{flashcardname:fashcard data,flashcardname:flashcard data...........................................},quiz{Q1:  question1,   options,correct answer, Q2:question2,options, correct answer...}..other structred output schema}} .now i will givve that structured output to frontend dev to showcas as flashcards....etc.   now tell me which techstack is best for my project and give me effective suggestions in functionalitiess,components.........etc.